{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get adjectives related to male and female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "bY4RMFQxrWyv",
    "outputId": "7926df4a-0561-4111-95a0-2a41ddc89e38"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations, filterfalse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.core import indexing\n",
    "from gender_predictor.GenderClassifier import classify_gender\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing as mp\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = pd.read_csv('movie.metadata.tsv', sep='\\t', skip_blank_lines=True, header=None, names=['id', 'free_id', 'movie_name', 'release_date', 'revenue', 'runtime', 'languages', 'countries', 'genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character = pd.read_csv('character.metadata.tsv', sep='\\t', skip_blank_lines=True, header=None, names=['id', 'free_id', 'release_date','char_name', 'dob', 'gender', 'height', 'ethnicity', 'name', 'age', 'free_char_id1', 'free_char_id2', 'free_char_id3'])\n",
    "character = character[['id', 'char_name', 'gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data['release_year'] = movie_data['release_date'].apply(lambda r:r[:4] if str(r)!='nan' else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id_by_year = {'United States of America':{}, 'India':{}}\n",
    "\n",
    "for index, row in movie_data.iterrows():\n",
    "    for key, value in json.loads(row['countries']).items():            \n",
    "        if value == 'United States of America' or value == 'India':\n",
    "            if row['release_year'] not in movie_id_by_year[value]:\n",
    "                movie_id_by_year[value][row['release_year']] = [row.id]\n",
    "            else:\n",
    "                movie_id_by_year[value][row['release_year']].append(row.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [i for i in movie_id_by_year['India'].keys() if i is not None and i<'2000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decade_2000 = []\n",
    "for c in count:\n",
    "    decade_2000 += movie_id_by_year['India'][c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(decade_2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_words = ['she', 'her', 'woman', 'women', 'ladies', 'girls', 'lady', 'aunt', 'grandmother', 'female', 'girl', 'damsel', 'maiden', 'daughter', 'sister', 'mother']\n",
    "male_words   = ['he', 'his', 'man', 'male', 'men', 'boys', 'gentleman', 'uncle', 'grandfather', 'gentlemen', 'boy', 'bloke', 'brother', 'father']\n",
    "verbs        = ['VB', 'VBP', 'VBZ', 'VBN']\n",
    "adj          = ['JJ']\n",
    "\n",
    "def read_input_file(filename):\n",
    "    data_df = pd.read_csv(filename,sep=',', skip_blank_lines=True, index_col= False)\n",
    "    return data_df\n",
    "\n",
    "\n",
    "def get_plots_by_movie_id(data_df):\n",
    "    movie_ids = data_df.movie_id.unique() \n",
    "    grouped = data_df.groupby(data_df.movie_id)\n",
    "\n",
    "    all_movie_plots = []\n",
    "    for id in movie_ids:\n",
    "        sents_df = grouped.get_group(id)\n",
    "        all_movie_plots.append(sents_df)\n",
    "    return all_movie_plots\n",
    "\n",
    "\n",
    "def get_frequency_for_movie(movie, attribute_type):\n",
    "    \n",
    "    if movie.iloc[0]['movie_id'] not in decade_2000:\n",
    "        return\n",
    "    \n",
    "    frequency_list = {'M':defaultdict(int), 'F':defaultdict(int)}\n",
    "    name_data  = movie[((movie.dep_pos == 'NNP') & (movie.dep_ner == 'PERSON')) | (movie.dependent.isin(female_words)) | (movie.dependent.isin(male_words))]\n",
    "    char_list  = character[character.id==movie.iloc[0]['movie_id']]\n",
    "    if attribute_type == \"verb\":\n",
    "        attribute_list = verb\n",
    "    else:\n",
    "        attribute_list = adj\n",
    "    gender_list = {}\n",
    "    for idx,name in name_data.iterrows():            \n",
    "        try:\n",
    "            character_name = name['dependent'].lower()\n",
    "            gender = None\n",
    "            if character_name in gender_list:\n",
    "                gender = gender_list[character_name]\n",
    "            elif character_name in female_words:\n",
    "                gender = 'F'\n",
    "            elif character_name in male_words:\n",
    "                gender = 'M'\n",
    "            else:\n",
    "                for ix, char in char_list.iterrows():\n",
    "                    chk = str(char['char_name'])\n",
    "                    if character_name in chk.lower():\n",
    "                        gender = char['gender']\n",
    "                        break\n",
    "                    \n",
    "                if gender is None:\n",
    "                    gender = classify_gender(character_name)\n",
    "                    \n",
    "            gender_list[character_name] = gender\n",
    "            governor = int(name['governor'])\n",
    "            governor_df = movie[(movie['sentence_id']==name['sentence_id']) & (movie['token_id'] == governor) & (movie['dep_pos'].isin(attribute_list))]\n",
    "            df2 = movie[(movie['sentence_id']==name['sentence_id']) & (movie['governor'] == name['token_id'])  & (movie['dep_pos'].isin(attribute_list))]\n",
    "            df3 = movie[(movie['sentence_id'] == name['sentence_id']) & (movie['governor']==name['governor']) & (movie['dep_pos'].isin(attribute_list))]\n",
    "            y = pd.concat([governor_df, df2, df3]).drop_duplicates()\n",
    "            for i, x in y.iterrows():\n",
    "                frequency_list[gender][x['dependent']] +=1\n",
    "        except Exception as exc:\n",
    "            pass\n",
    "    print(movie.iloc[0]['movie_id'])\n",
    "    print(frequency_list)\n",
    "    return frequency_list\n",
    "    \n",
    "def get_name_and_adjective_mapping(all_movie_plots, attribute_type):\n",
    "    frequency_list = {'M':defaultdict(int), 'F':defaultdict(int)}\n",
    "    pool = mp.Pool(20)\n",
    "    results = [pool.apply_async(get_frequency_for_movie, args=(movie,)) for movie in all_movie_plots]    \n",
    "    output = [p.get() for p in results]\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_adjective_cloud(filename, attribute_type=\"verb\"):\n",
    "    movie_data_df = read_input_file(filename)\n",
    "    all_movie_plots = get_plots_by_movie_id(movie_data_df)\n",
    "    name_adj_cluster_list = get_name_and_adjective_mapping(all_movie_plots, attribute_type)\n",
    "    return name_adj_cluster_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time result = get_adjective_cloud('india_lemma.csv', \"adj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save frequency\n",
    "import pickle\n",
    "output = open('india_before_2000_verb.pkl', 'wb')\n",
    "pickle.dump(frequency_list, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Frequency from file\n",
    "import pickle\n",
    "pkl_file = open('india_before_2000_verb.pkl', 'rb')\n",
    "\n",
    "frequency_list = pickle.load(pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine frequency from different results\n",
    "frequency_list = {'M':defaultdict(int),'F':defaultdict(int)}\n",
    "\n",
    "for freq in result:\n",
    "    if freq is None:\n",
    "        continue\n",
    "    for k, v in freq['M'].items():\n",
    "        frequency_list['M'][k]+=v\n",
    "    for k, v in freq['F'].items():\n",
    "        frequency_list['F'][k]+=v  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Odds Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_ratio = {}\n",
    "threshold  = 2\n",
    "topk       = 50\n",
    "\n",
    "total_num_f = sum(frequency_list['F'].values())\n",
    "total_num_m = sum(frequency_list['M'].values())\n",
    "\n",
    "for key in frequency_list['F'].keys():\n",
    "    m_num = frequency_list['M'][key]\n",
    "    f_num = frequency_list['F'][key]\n",
    "    non_f_num = total_num_f - f_num\n",
    "    non_m_num = total_num_m - m_num\n",
    "    if f_num >= threshold and m_num >= threshold:\n",
    "        # we only consider the events where there are at least {thresohld} occurences for both gender\n",
    "        odds_ratio[key] = round((m_num / f_num) / (non_m_num / non_f_num), 2)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "top_m = dict(sorted(odds_ratio.items(), key=itemgetter(1), reverse=True)[:topk])\n",
    "top_f = dict(sorted(odds_ratio.items(), key=itemgetter(1))[:topk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = KeyedVectors.load_word2vec_format('embeddings/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "words1 = [\"she\", \"her\", \"woman\", \"women\"]\n",
    "words2 = [\"he\", \"him\", \"his\", \"man\", \"men\"]\n",
    "words_list = list(top_m.keys()) + list(top_f.keys())\n",
    "\n",
    "sim_m = []\n",
    "sim_f = []\n",
    "for word in words_list:\n",
    "    res = []\n",
    "    for w in words2:\n",
    "        if w in glove.key_to_index and word in glove.key_to_index:\n",
    "            res.append(cosine_similarity([glove[word]],[glove[w]])[0][0])\n",
    "    if len(res)>0:\n",
    "        mean = np.mean(res)\n",
    "        if mean and mean>0:\n",
    "            sim_m.append(mean)\n",
    "    res = []     \n",
    "    for w in words2:\n",
    "        if w in glove.key_to_index and word in glove.key_to_index:\n",
    "            res.append(cosine_similarity([glove[word]],[glove[w]])[0][0])\n",
    "    if len(res)>0:\n",
    "        mean = np.mean(res)\n",
    "        if mean and mean>0:\n",
    "            sim_f.append(mean)\n",
    "            \n",
    "print(sim_f)\n",
    "\n",
    "print(sim_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "x_coordinates = sim_m[:10]\n",
    "y_coordinates = sim_f[:10]\n",
    "\n",
    "plt.figure(figsize=(8, 8), dpi=300)\n",
    "sns.set(style='whitegrid')\n",
    "sns.despine()\n",
    "plt.scatter(x_coordinates, y_coordinates)\n",
    "\n",
    "for i, x in enumerate(x_coordinates):\n",
    "    plt.annotate(words_list[i], (x, y_coordinates[i]))\n",
    "    \n",
    " \n",
    "# naming the x axis\n",
    "plt.xlabel('Male')\n",
    "# naming the y axis\n",
    "plt.ylabel('Female')\n",
    " \n",
    "# giving a title to my graph\n",
    "plt.title('Cosine Similarities')\n",
    " \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "WEAT (Final).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
