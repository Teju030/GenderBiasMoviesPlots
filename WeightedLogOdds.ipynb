{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247579a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"India_event_chain_by_each_year.json\") as f:\n",
    "    result = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine frequency from different results\n",
    "frequency_list = {'M':list(),'F':list()}\n",
    "\n",
    "for year in result:\n",
    "    # Fill in the desired decade\n",
    "    if year and year.isdigit() and int(year) < 2000:\n",
    "        for freq in result[year]:\n",
    "            if freq is None:\n",
    "                continue\n",
    "            frequency_list['M'].append(\". \".join(freq['M']))\n",
    "            frequency_list['F'].append(\". \".join(freq['F']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae13d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "def basic_sanitize(in_string):\n",
    "    '''Returns a very roughly sanitized version of the input string.'''  \n",
    "    in_string = ''.join([ch for ch in in_string if ch not in exclude])\n",
    "    in_string = in_string.lower()\n",
    "    in_string = ' '.join(in_string.split())\n",
    "    return in_string\n",
    "\n",
    "def weighted_log_odds_ratio(l1, l2, ngram = 1, prior=.01, cv = None):\n",
    "    '''\n",
    "    Arguments:\n",
    "    - l1, l2; a list of strings from each language sample\n",
    "    - ngram; an int describing up to what n gram you want to consider (1 is unigrams,\n",
    "    2 is bigrams + unigrams, etc). Ignored if a custom CountVectorizer is passed.\n",
    "    - prior; either a float describing a uniform prior, or a vector describing a prior\n",
    "    over vocabulary items. If you're using a predefined vocabulary, make sure to specify that\n",
    "    when you make your CountVectorizer object.\n",
    "    - cv; a sklearn.feature_extraction.text.CountVectorizer object, if desired.\n",
    "    Returns:\n",
    "    - A list of length |Vocab| where each entry is a (n-gram, zscore) tuple.'''\n",
    "    if cv is None and type(prior) is not float:\n",
    "        print(\"If using a non-uniform prior:\")\n",
    "        print(\"Please also pass a count vectorizer with the vocabulary parameter set.\")\n",
    "        quit()\n",
    "    l1 = [basic_sanitize(l) for l in l1]\n",
    "    l2 = [basic_sanitize(l) for l in l2]\n",
    "    if cv is None:\n",
    "        cv = CV(decode_error = 'ignore', ngram_range=(ngram, ngram),\n",
    "                binary = False,\n",
    "                max_features = 15000)\n",
    "    counts_mat = cv.fit_transform(l1+l2).toarray()\n",
    "    # Now sum over languages...\n",
    "    vocab_size = len(cv.vocabulary_)\n",
    "    print(\"Vocab size is {}\".format(vocab_size))\n",
    "    if type(prior) is float:\n",
    "        priors = np.array([prior for i in range(vocab_size)])\n",
    "    else:\n",
    "        priors = prior\n",
    "    z_scores = np.empty(priors.shape[0])\n",
    "    count_matrix = np.empty([2, vocab_size], dtype=np.float32)\n",
    "    count_matrix[0, :] = np.sum(counts_mat[:len(l1), :], axis = 0)\n",
    "    count_matrix[1, :] = np.sum(counts_mat[len(l1):, :], axis = 0)\n",
    "    a0 = np.sum(priors)\n",
    "    n1 = 1.*np.sum(count_matrix[0,:])\n",
    "    n2 = 1.*np.sum(count_matrix[1,:])\n",
    "    print(\"Comparing language...\")\n",
    "    for i in range(vocab_size):\n",
    "        #compute delta\n",
    "        term1 = np.log((count_matrix[0,i] + priors[i])/(n1 + a0 - count_matrix[0,i] - priors[i]))\n",
    "        term2 = np.log((count_matrix[1,i] + priors[i])/(n2 + a0 - count_matrix[1,i] - priors[i]))        \n",
    "        delta = term1 - term2\n",
    "        #compute variance on delta\n",
    "        var = 1./(count_matrix[0,i] + priors[i]) + 1./(count_matrix[1,i] + priors[i])\n",
    "        #store final score\n",
    "        z_scores[i] = delta/np.sqrt(var)\n",
    "    index_to_term = {v:k for k,v in cv.vocabulary_.items()}\n",
    "    sorted_indices = np.argsort(z_scores)\n",
    "    return_list = []\n",
    "    for i in sorted_indices:\n",
    "        return_list.append((index_to_term[i], z_scores[i]))\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f47616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unigrams - anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_ratio = bayes_compare_language(frequency_list['M'], frequency_list['F'], 1)\n",
    "\n",
    "from operator import itemgetter\n",
    "topk = 250\n",
    "top_m = dict(sorted(odds_ratio, key=itemgetter(1), reverse=True)[:topk])\n",
    "top_f = dict(sorted(odds_ratio, key=itemgetter(1))[:topk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77346e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cda0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['the', 'son', 'she', 'her', 'woman', 'women', 'ladies', 'girls', 'lady', 'aunt', 'grandmother', 'female', 'girl', 'damsel', 'maiden', 'daughter', 'sister', 'mother', 'he', 'his', 'man', 'male', 'men', 'boys', 'gentleman', 'uncle', 'grandfather', 'gentlemen', 'boy', 'bloke', 'brother', 'father', 'their', 'they']\n",
    "\n",
    "x = []\n",
    "for word in top_f.keys():\n",
    "    if word not in words and 'attime' not in word:\n",
    "        x.append(word)\n",
    "pruned_f = list(x)\n",
    "\n",
    "x = []\n",
    "for word in top_m.keys():\n",
    "    if word not in words and 'attime' not in word:\n",
    "        x.append(word)\n",
    "pruned_m = list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdad2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b257c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cfbc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_ratio = bayes_compare_language(frequency_list['M'], frequency_list['F'], 2)\n",
    "\n",
    "from operator import itemgetter\n",
    "top_m = dict(sorted(odds_ratio, key=itemgetter(1), reverse=True))\n",
    "top_f = dict(sorted(odds_ratio, key=itemgetter(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b6efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Male Bigrams\n",
    "x = []\n",
    "count = 250\n",
    "for word in top_m:\n",
    "    words = word.split(' ')\n",
    "    if words[0] == words[1]:\n",
    "        continue\n",
    "    if words[0] in pruned_m[:1000] + pruned_f[:1000] and words[1] in pruned_m[:1000] + pruned_f[:1000]:        \n",
    "        count-=1\n",
    "        x.append(word)\n",
    "    if count==0:\n",
    "        break\n",
    "json.dumps(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Female Bigrams\n",
    "x = []\n",
    "count = 250\n",
    "for word in top_f:\n",
    "    words = word.split(' ')\n",
    "    if words[0] == words[1]:\n",
    "        continue\n",
    "    if words[0] in pruned_m[:1000] + pruned_f[:1000] and words[1] in pruned_m[:1000] + pruned_f[:1000]:        \n",
    "        count-=1\n",
    "        x.append(word)\n",
    "    if count==0:\n",
    "        break\n",
    "json.dumps(x)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
